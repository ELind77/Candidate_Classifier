{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from spacy.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/Storage/Coding_Projects/Candidate_Classifier'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/Storage/Coding_Projects/Candidate_Classifier'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (ngram.py, line 126)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"candidate_classifier/nltk_model/ngram.py\"\u001b[1;36m, line \u001b[1;32m126\u001b[0m\n\u001b[1;33m    if not isinstance(nxt2)\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from candidate_classifier.nltk_model import NgramModel\n",
    "from candidate_classifier import utils\n",
    "from nltk.probability import LaplaceProbDist, LidstoneProbDist\n",
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from candidate_classifier.debate_corpus_reader import DebateCorpusReader\n",
    "from candidate_classifier.string_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = English(load_vectors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransformerWrapper(object):\n",
    "    def __init__(self, transformer):\n",
    "        self.transformer = transformer\n",
    "    \n",
    "    def tokenize(self, s):\n",
    "        return self.transformer(s)\n",
    "\n",
    "class DummyTokenizer(object):\n",
    "    def tokenize(self, s):\n",
    "        return s\n",
    "    \n",
    "def sent_tokenizer(s):\n",
    "    doc = nlp(s)\n",
    "    return [u''.join(t.text_with_ws for t in sent) for sent in doc.sents]\n",
    "\n",
    "\n",
    "# def word_tokenizer(s):\n",
    "#     toks = nlp(s)\n",
    "#     return ['<S>'] + [t.lower_ for t in toks] + ['</S>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace [*] with ''\n",
    "# Replace '. . .' with '...'\n",
    "# Replace multiple ellipses with single ...\n",
    "# Remove all sentences that end with ...\n",
    "\n",
    "BRACKET_PATTERN = re.compile(r\"\\[[a-zA-Z ]*\\]\", re.U)\n",
    "SPACED_ELLIPSIS_PATTERN = re.compile(r\"((?:\\.\\s){3})\")\n",
    "MULTI_ELLIPSIS_PATTERN = re.compile(r\"(?:(?:\\.){3} ?)+\")\n",
    "ELLIPSIS_BRACKET_PATTERN = re.compile(r\"(?:(?:\\.){3}) *\\[[a-zA-Z ]*\\] *(?:(?:\\.){3} ?)\")\n",
    "ENDS_WITH_ELLIPSIS = lambda s: s[-3:] == '...'\n",
    "STARTS_WITH_ELLIPSIS = lambda s: s[:3] == '...'\n",
    "STARTS_WITH_DASH = lambda s: s[0] == '-'\n",
    "ENDS_WITH_DASH = lambda s: s[-1] == '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_transformer = TransformerABC(\n",
    "    prefilter_substitutions=['html entities',\n",
    "                             'deaccent',\n",
    "                             'whitespace',\n",
    "                             (ELLIPSIS_BRACKET_PATTERN, ' '),\n",
    "                             BRACKET_PATTERN,\n",
    "                             (SPACED_ELLIPSIS_PATTERN, '...'),\n",
    "                             (MULTI_ELLIPSIS_PATTERN, '...'),\n",
    "                             'whitespace',\n",
    "                             'strip'],\n",
    "    tokenizer=sent_tokenizer)\n",
    "\n",
    "sent_filter = TransformerABC(\n",
    "    prefilter_substitutions=['puntuation', 'strip'],\n",
    "    filters=[('len', 49)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d1de8ec0acab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m dcr = DebateCorpusReader('candidate_classifier/data/raw', '.*\\.txt', \n\u001b[1;32m----> 2\u001b[1;33m                              \u001b[0msent_tokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTransformerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_transformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m                              word_tokenizer=DummyTokenizer())\n\u001b[0;32m      4\u001b[0m \u001b[0mcandidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'BUSH'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CARSON'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CHRISTIE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CRUZ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'KASICH'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RUBIO'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TRUMP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CLINTON'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SANDERS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc_transformer' is not defined"
     ]
    }
   ],
   "source": [
    "dcr = DebateCorpusReader('candidate_classifier/data/raw', '.*\\.txt', \n",
    "                             sent_tokenizer=TransformerWrapper(doc_transformer), \n",
    "                             word_tokenizer=DummyTokenizer())\n",
    "candidates = ['BUSH', 'CARSON', 'CHRISTIE', 'CRUZ', 'KASICH', 'RUBIO', 'TRUMP', 'CLINTON', 'SANDERS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess to sentences\n",
    "I have officially decided that the task is classifying sentences and snippits.  As such, each document will be a sentence.  \n",
    "\n",
    "#### Precrocessing Steps\n",
    "- Tokenize to sentences and normalize encoding\n",
    "- remove all non-ascii characters\n",
    "- All whitespace to spaces (no newlines)\n",
    "- Filter all sentences that are less than 50 characters (after removing all punctuation)\n",
    "- Group all sentences together with their labels and shuffle them\n",
    "- Write text and labels to (separate) line-delimited files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents_path = 'candidate_classifier/data/processed/clean_sents.txt'\n",
    "labels_path = 'candidate_classifier/data/processed/sent_labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_sents = []\n",
    "for label, sents in dcr.grouped_sents(speakers=candidates).iteritems():\n",
    "    for sent in sents:\n",
    "#             stripped = sent.strip(string.punctuation+ ' \\n\\t')\n",
    "#             if len(stripped) >= 35:\n",
    "#                 cleaned_sents.append((label, sent))\n",
    "        if sent_filter(sent):\n",
    "            cleaned_sents.append((label, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8851"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(cleaned_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "sents_file = codecs.open(sents_path, mode='w', encoding='utf-8')\n",
    "labels_file = codecs.open(labels_path, mode='w', encoding='utf-8')\n",
    "    \n",
    "for sent in cleaned_sents:\n",
    "    sents_file.write(u'%s\\n' % sent[1])\n",
    "    labels_file.write(u'%s\\n' % sent[0])\n",
    "\n",
    "sents_file.close()\n",
    "labels_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_stats(dcr, filt, speakers=None):\n",
    "    \"\"\"\n",
    "    Returns a dictionary for the given speakers with stats for all sentences\n",
    "    dcr is a DebateCorpusReader\n",
    "    filt is a callable that will turn sentences we want to filter into a falsy value\n",
    "    \"\"\"\n",
    "    if speakers is None:\n",
    "        speakers = dcr.speakers()\n",
    "    stats = {s:dict() for s in speakers}\n",
    "    \n",
    "    for speaker, sents in dcr.grouped_sents(speakers=speakers).iteritems():\n",
    "        stats[speaker]['count'] = len(sents)\n",
    "        lengths = [len(s) for s in sents]\n",
    "        mean_length = np.mean(lengths)\n",
    "        std = np.std(lengths)\n",
    "        stats[speaker]['length'] = '%0.2f (+/- %0.2f)' % (mean_length, std*1.960)\n",
    "    \n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_stats = sentence_stats(dcr, sent_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUMP                2647       57.55 (+/- 91.10)   \n",
      "SANDERS              1948       90.94 (+/- 144.33)  \n",
      "CLINTON              1867       102.53 (+/- 147.05) \n",
      "RUBIO                1833       87.63 (+/- 119.96)  \n",
      "CRUZ                 1504       90.61 (+/- 131.77)  \n",
      "KASICH               1410       80.09 (+/- 124.65)  \n",
      "BUSH                 1374       78.07 (+/- 115.14)  \n",
      "CHRISTIE             961        86.49 (+/- 126.81)  \n",
      "CARSON               907        88.96 (+/- 122.32)  \n",
      "PAUL                 704        76.77 (+/- 100.19)  \n",
      "FIORINA              546        80.49 (+/- 120.56)  \n",
      "MUIR                 510        71.71 (+/- 124.24)  \n",
      "DICKERSON            485        73.13 (+/- 116.95)  \n",
      "BLITZER              456        50.85 (+/- 92.77)   \n",
      "TAPPER               429        56.00 (+/- 95.77)   \n",
      "COOPER               427        68.51 (+/- 114.06)  \n",
      "RADDATZ              321        78.61 (+/- 118.99)  \n",
      "HUCKABEE             270        87.93 (+/- 128.88)  \n",
      "KELLY                246        70.84 (+/- 120.65)  \n",
      "BAIER                246        69.13 (+/- 108.46)  \n",
      "HOLT                 244        77.03 (+/- 121.93)  \n",
      "BARTIROMO            228        62.58 (+/- 92.57)   \n",
      "CAVUTO               221        73.48 (+/- 126.41)  \n",
      "WALLACE              218        87.00 (+/- 128.28)  \n",
      "WALKER               205        89.07 (+/- 131.77)  \n",
      "BASH                 184        64.39 (+/- 102.15)  \n",
      "HEWITT               168        60.92 (+/- 98.34)   \n",
      "WEBB                 166        95.67 (+/- 156.82)  \n",
      "TODD                 156        72.14 (+/- 126.72)  \n",
      "QUINTANILLA          140        51.94 (+/- 101.41)  \n",
      "CHAFEE               139        66.40 (+/- 116.64)  \n",
      "QUICK                138        56.41 (+/- 93.35)   \n",
      "HARWOOD              122        64.58 (+/- 125.55)  \n",
      "MADDOW               108        96.61 (+/- 138.08)  \n",
      "BAKER                105        67.37 (+/- 129.39)  \n",
      "WOODRUFF             79         75.33 (+/- 136.83)  \n",
      "MITCHELL             79         65.62 (+/- 121.36)  \n",
      "IFILL                75         76.83 (+/- 104.97)  \n",
      "GARRETT              51         75.63 (+/- 132.59)  \n",
      "CORDES               43         60.63 (+/- 85.59)   \n",
      "COONEY               43         83.33 (+/- 122.54)  \n",
      "HAM                  42         70.31 (+/- 110.52)  \n",
      "MCELVEEN             40         73.67 (+/- 98.73)   \n",
      "STRASSEL             38         74.87 (+/- 115.17)  \n",
      "EPPERSON             31         78.74 (+/- 80.59)   \n",
      "QUESTION             29         95.62 (+/- 99.37)   \n",
      "LEVESQUE             29         85.79 (+/- 76.12)   \n",
      "LEMON                28         67.25 (+/- 119.12)  \n",
      "LOPEZ                24         85.75 (+/- 120.57)  \n",
      "UNKNOWN              23         34.70 (+/- 62.32)   \n",
      "OBRADOVICH           18         82.83 (+/- 100.75)  \n",
      "SANTELLI             13         55.00 (+/- 77.79)   \n",
      "CRAMER               11         74.91 (+/- 92.64)   \n",
      "ANNOUNCER            9          99.22 (+/- 123.31)  \n",
      "UNIDENTIFIED MALE    8          45.62 (+/- 63.01)   \n",
      "BROWNLEE             5          89.80 (+/- 75.46)   \n",
      "FRANCHESCA RAMSEY    4          93.50 (+/- 78.17)   \n",
      "FRANTA               4          77.50 (+/- 12.89)   \n",
      "PERRY                3          117.33 (+/- 73.71)  \n",
      "UNIDENTIFIED FEMALE  3          117.00 (+/- 26.34)  \n",
      "???                  3          43.67 (+/- 34.41)   \n",
      "MODERATOR            2          69.00 (+/- 115.64)  \n",
      "WILKINS              2          48.00 (+/- 64.68)   \n",
      "AUDIENCE             2          4.50 (+/- 0.98)     \n",
      "UNIDENTIFIED         1          27.00 (+/- 0.00)    \n",
      "MALE                 1          18.00 (+/- 0.00)    \n"
     ]
    }
   ],
   "source": [
    "# NB: This is actually a poisson distribution, so I should be reporting it a bit differently than \n",
    "# the +-\n",
    "for tup in sorted(sent_stats.iteritems(), key=lambda tup: tup[1]['count'], reverse=True):\n",
    "#     print \"%s\\t\\t\\tcount: %s\\tlength: %s\" % (tup[0], tup[1]['count'], tup[1]['length'])\n",
    "    print \"{: <20} {: <10} {: <20}\".format(tup[0], tup[1]['count'], tup[1]['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import make_scorer, classification_report, f1_score\n",
    "import codecs\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'BUSH', u'CARSON', u'CHRISTIE', u'CLINTON', u'CRUZ', u'KASICH', u'RUBIO', u'SANDERS', u'TRUMP']\n"
     ]
    }
   ],
   "source": [
    "def docs():\n",
    "    with codecs.open(sents_path, mode='r', encoding='utf-8') as _f:\n",
    "        for line in _f:\n",
    "            yield line\n",
    "\n",
    "def labels():\n",
    "    with codecs.open(labels_path, mode='r', encoding='utf-8') as _f:\n",
    "        for line in _f:\n",
    "            yield line.strip()\n",
    "labels_list = list(labels())\n",
    "candidates = sorted(list(set(labels_list)))\n",
    "docs_list = list(docs())\n",
    "print candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(clf, X, y):\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring='f1_samples')\n",
    "    print scores\n",
    "    print \"\\n\"\n",
    "    # Use 1.96 * std b/c 95% of the data should lie in that range, \n",
    "    # which means this represents a 95% confidence interval\n",
    "    print \"F1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 1.960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fancy_scorer(y, y_pred, **kwargs):\n",
    "    # Print classification report\n",
    "    print classification_report(y, y_pred, target_names=candidates)\n",
    "    return f1_score(y, y_pred, labels=candidates, average='weighted')    \n",
    "\n",
    "def f1_weighted_scorer(y, y_pred, **kwargs):\n",
    "    return f1_score(y, y_pred, labels=candidates, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_cleaner = TransformerABC(prefilter_substitutions=['strip', 'lower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_np(doc):\n",
    "    for np in doc.noun_chunks:\n",
    "        while len(np) > 1 and np[0].dep_ not in ('avmod', 'amod', 'compound'):\n",
    "            np = np[1:]\n",
    "        np.merge(np.root.tag_, np.text, np.root.ent_type_)\n",
    "    return doc\n",
    "\n",
    "def merge_ent(doc):\n",
    "    for ent in doc.ents:\n",
    "        # In the sense2vec code they do something a bit different with the entity label and I'm not sure why\n",
    "        ent.merge(ent.root.tag_, ent.text, ent.label_)\n",
    "    return doc\n",
    "\n",
    "def filter_features(toks, attrs):\n",
    "    return [t for t in toks if not any([getattr(t, a) for a in attrs])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import copy\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get paths that cross head-nodes\n",
    "\n",
    "\n",
    "def sn_grams(sent, m, n, prop='lemma_', spanning=False):\n",
    "    \"\"\"Get all syntactic ngrams from min length m to max length n\"\"\"\n",
    "    if spanning:\n",
    "        root = sent.root\n",
    "        return sn_spanning_helper([], deque([], n), root, m, prop=prop)\n",
    "    else:\n",
    "        root = sent.root\n",
    "        return sn_helper([], deque([], n), root, m, prop=prop)\n",
    "\n",
    "def sn_helper(acc, buff, curr, m, prop='lemma_'):\n",
    "    # Add curr\n",
    "    # But don't add ROOT because those relations occur in almost all sentences\n",
    "    # NB: No need to pop b/c deque has max length specified\n",
    "    if prop == 'dep_' and curr.dep_ == 'ROOT':\n",
    "        pass\n",
    "    else:\n",
    "        buff.appendleft(getattr(curr, prop))\n",
    "    \n",
    "    # Create the ngrams that end with the current node\n",
    "    # Having the n-grams in reverse lexical order is a bit odd \n",
    "    # for humans to read, but because it's deterministic, it \n",
    "    # shouldn't make any difference to the computer for using them as \n",
    "    # features\n",
    "#     gram = []\n",
    "#     if len(buff) >= m:\n",
    "#         for i, tok in enumerate(buff):\n",
    "#             # Build up the ngram\n",
    "#             gram.append(tok)\n",
    "#             # Only append ngrams >= the min length\n",
    "#             if len(gram) >= m:\n",
    "#                 acc.append('_'.join(reversed(gram)))\n",
    "    \n",
    "    # Optimized\n",
    "    gram = ''\n",
    "    count = 0\n",
    "    if len(buff) >= m:\n",
    "        for i, tok in enumerate(buff):\n",
    "            # Build up the ngram\n",
    "            gram += '_' + tok\n",
    "            count += 1\n",
    "            # Only append ngrams >= the min length\n",
    "            if count >= m:\n",
    "                acc.append(gram)\n",
    "    \n",
    "    # Add all childrens' ngrams\n",
    "    for c in curr.children:\n",
    "        # Add to acc with destructive modification \n",
    "        # but don't let children modify buffer because it needs \n",
    "        # to be in the same state for the next child of curr\n",
    "        sn_helper(acc, copy.copy(buff), c, m, prop=prop)\n",
    "    \n",
    "    # Return the accumulator\n",
    "    return acc\n",
    "        \n",
    "\n",
    "# TODO:re-write as iterative\n",
    "# TODO: I'm pretty sure this is a dynamic programming problem\n",
    "# TODO: skip POBJ?\n",
    "def sn_spanning_helper(acc, buff, curr, m, prop='lemma_'):\n",
    "#     print 'curr:', (getattr(curr, prop))\n",
    "    # Add curr\n",
    "    # But don't add ROOT because those relations occur in almost all sentences\n",
    "    # NB: No need to pop b/c deque has max length specified\n",
    "    if prop == 'dep_' and curr.dep_ == 'ROOT':\n",
    "        pass\n",
    "    else:\n",
    "        buff.append(curr)\n",
    "        buff = deque(sorted(buff, key=operator.attrgetter('idx')), buff.maxlen)\n",
    "        \n",
    "    # Create the ngrams that end with the current node\n",
    "    # Having the n-grams in reverse lexical order is a bit odd \n",
    "    # for humans to read, but because it's deterministic, it \n",
    "    # shouldn't make any difference to the computer for using them as \n",
    "    # features\n",
    "    gram = []\n",
    "    if len(buff) >= m:\n",
    "        for i, tok in enumerate(buff):\n",
    "            # Build up the ngram\n",
    "#             gram.append(tok)\n",
    "            gram.append(getattr(tok, prop))\n",
    "            # Only append ngrams >= the min length\n",
    "            if len(gram) >= m:\n",
    "                acc.append('_'.join(gram))\n",
    "    \n",
    "    if curr.n_lefts > 0:\n",
    "        # Add all left ngrams\n",
    "        for c in curr.lefts:\n",
    "            # Don't revisit self\n",
    "            if c is curr:\n",
    "                continue\n",
    "            # Add to acc with destructive modification \n",
    "            # but don't let children modify buffer because it needs \n",
    "            # to be in the same state for the next child of curr\n",
    "            sn_spanning_helper(acc, copy.copy(buff), c, m, prop=prop)\n",
    "    else:\n",
    "        # Add all right ngrams\n",
    "        for c in curr.rights:\n",
    "            # Add to acc with destructive modification \n",
    "            # but don't let children modify buffer because it needs \n",
    "            # to be in the same state for the next child of curr\n",
    "            sn_spanning_helper(acc, copy.copy(buff), c, m, prop=prop)\n",
    "\n",
    "    # Now, decend the parent's rights\n",
    "    # So long as this isn't the root\n",
    "    if curr.head is curr:\n",
    "        return acc\n",
    "    else:\n",
    "        for c in curr.head.rights:\n",
    "            # Don't revisit self\n",
    "            if c is curr:\n",
    "                continue\n",
    "            sn_spanning_helper(acc, copy.copy(buff), c, m, prop=prop)\n",
    "    \n",
    "    # Return the accumulator\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sn_grams(doc, prop, spanning=False):\n",
    "    result = []\n",
    "    for sent in doc.sents:\n",
    "        result.extend(sn_grams(sent, 1, 3, prop=prop, spanning=spanning))\n",
    "    return result\n",
    "\n",
    "def sn_tokenizer(s):\n",
    "    return get_sn_grams(nlp(s), 'lemma_')\n",
    "\n",
    "def sn_pos_tokenizer(s):\n",
    "    return get_sn_grams(nlp(s), 'tag_')\n",
    "\n",
    "def sn_merge_ents(s):\n",
    "    doc = merge_ent(nlp(s))\n",
    "    return get_sn_grams(doc, 'lemma_')\n",
    "\n",
    "def sn_pos_merge_ent(s):\n",
    "    doc = merge_ent(nlp(s))\n",
    "    return get_sn_grams(doc, 'tag_')\n",
    "\n",
    "def sn_merge_np(s):\n",
    "    doc = merge_np(nlp(s))\n",
    "    return get_sn_grams(doc, 'lemma_')\n",
    "\n",
    "def sn_sr_tokenizer(s):\n",
    "    return get_sn_grams(nlp(s), 'dep_')\n",
    "\n",
    "def sn_sr_merge_ent(s):\n",
    "    doc = merge_ent(nlp(s))\n",
    "    return get_sn_grams(nlp(s), 'dep_')\n",
    "\n",
    "def sn_spanning_tokenizer(s):\n",
    "    return get_sn_grams(nlp(s), 'lemma_', spanning=True)\n",
    "    \n",
    "def sn_spanning_merge_ents(s):\n",
    "    doc = merge_ent(nlp(s))\n",
    "    return get_sn_grams(nlp(s), 'lemma_', spanning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_tokenizer(s):\n",
    "    return s.split()\n",
    "\n",
    "def lemmas_tokenizer(s):\n",
    "    return [t.lemma_ for t in nlp(s) if not t.is_space]\n",
    "\n",
    "def lemmas_no_punct(s):\n",
    "    return [t.lemma_ for t in nlp(s) if not any([t.is_punct, t.is_space])]\n",
    "\n",
    "def lemmas_no_punt_no_num(s):\n",
    "    return [t.lemma_ for t in nlp(s) if not any([t.is_punct, t.is_space, t.is_digit, t.is_like_num])]\n",
    "\n",
    "def lemmas_sub_nums(s):\n",
    "    pass\n",
    "\n",
    "def lemmas_no_punct_sub_nums(s):\n",
    "    pass\n",
    "\n",
    "# Spacy tokenization, no lemmatization\n",
    "# replace candidate and person names with PERSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmas_merge_np(s):\n",
    "    toks = merge_np(nlp(s))\n",
    "    return [t.lemma_ for t in toks if not t.is_space]\n",
    "\n",
    "def lemmas_merge_ents(s):\n",
    "    toks = merge_ent(nlp(s))\n",
    "    return [t.lemma_ for t in toks if not t.is_space]\n",
    "\n",
    "def lemmas_merge_np_merge_ents(s):\n",
    "    toks = merge_ent(nlp(s))\n",
    "    toks = merge_np(toks)\n",
    "    return [t.lemma_ for t in toks if not t.is_space]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmas_cased_tokenizer(s):\n",
    "    \"\"\"Tokenizer that lematizes but preserves the case of the first letter of tokens\"\"\"\n",
    "    toks = nlp(s)\n",
    "    return [t.lemma_.title() if t.is_title else t.lemma_ for t in toks]\n",
    "\n",
    "def lemmas_cased_merge_ents(s):\n",
    "    toks = merge_ent(nlp(s))\n",
    "    return [t.lemma_.title() if t.is_title else t.lemma_ for t in toks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So these were basically useless.  I'm pretty sure I'm using them wrong...\n",
    "\n",
    "def get_brown(doc):\n",
    "    out = []\n",
    "    for t in doc:\n",
    "        if not t.is_space:\n",
    "            # Should use tok.ent_iob_\n",
    "            if t.cluster != 0 and t.tag_ != 'NNP':\n",
    "                out.append(\"**%s**\" % t.cluster)\n",
    "            else:\n",
    "                out.append(t.lemma_)\n",
    "    return out\n",
    "\n",
    "def brown_cluster_tokenizer(s):\n",
    "    toks = nlp(s)\n",
    "    return get_brown(toks)\n",
    "    \n",
    "\n",
    "def brown_cluster_merge_ents(s):\n",
    "    toks = merge_ent(nlp(s))\n",
    "    return get_brown(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk_stops = ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnb_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=simple_cleaner, token_pattern=r\".*\")),\n",
    "        ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "sgd_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=simple_cleaner, token_pattern=r\".*\")),\n",
    "        ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=simple_cleaner, token_pattern=r\".*\")),\n",
    "        ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=simple_cleaner, token_pattern=r\".*\")),\n",
    "        ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "# TODO:\n",
    "# - TFIDF\n",
    "# - log-count ratio?\n",
    "# - binarize\n",
    "# Chi-squared?\n",
    "\n",
    "pipes = [mnb_pipe, sgd_pipe, rf_pipe, svm_pipe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnb_grid_params = {\n",
    "    'vect__ngram_range': ((1,1),(1,2),(1,3)),\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__tokenizer': (simple_tokenizer, lemmas_tokenizer, lemmas_no_punct),\n",
    "    'clf__alpha': (0.001, 0.01, 0.1, 1)\n",
    "}\n",
    "\n",
    "mnb_tokenization_grid_params = {\n",
    "    'vect__ngram_range': ((1,1),(1,3)),\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__tokenizer': (simple_tokenizer,\n",
    "                        lemmas_tokenizer, \n",
    "                        lemmas_no_punct,\n",
    "                        lemmas_merge_np,\n",
    "                        lemmas_merge_ents,\n",
    "                        lemmas_merge_np_merge_ents\n",
    "                       ),\n",
    "    'clf__alpha': (0.075, 0.1)\n",
    "}\n",
    "\n",
    "mnb_brown_grid_params = {\n",
    "    'vect__ngram_range': ((1,1),(1,3)),\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__tokenizer': (lemmas_tokenizer, \n",
    "                        lemmas_no_punct,\n",
    "                        lemmas_merge_ents,\n",
    "                        brown_cluster_tokenizer,\n",
    "                        brown_cluster_merge_ents\n",
    "                       ),\n",
    "    'clf__alpha': (0.075, 0.1)\n",
    "}\n",
    "\n",
    "\n",
    "mnb_sn_grid_params = {\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__tokenizer': (sn_tokenizer,\n",
    "                        sn_pos_tokenizer,\n",
    "                        sn_merge_ents,\n",
    "                        sn_pos_merge_ent,\n",
    "                        sn_merge_np,\n",
    "                        sn_sr_tokenizer,\n",
    "                        sn_sr_merge_ent,\n",
    "                        sn_spanning_tokenizer,\n",
    "                        sn_spanning_merge_ents\n",
    "                       ),\n",
    "    'clf__alpha': (0.075, 0.1)\n",
    "}\n",
    "\n",
    "\n",
    "# This is really too many parameters\n",
    "# Apparently l2 loss is depricated and I should use squared_hinge\n",
    "sgd_grid_params = {\n",
    "    'vect__ngram_range': ((1,1),(1,2),(1,3)),\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__tokenizer': (lemmas_tokenizer, lemmas_no_punct),\n",
    "    'clf__loss': ('hinge', 'log', 'perceptron'),\n",
    "    'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
    "    'clf__alpha': (0.0001, 0.00001, 0.000001),\n",
    "    'clf__l1_ratio': (0.15, 0.05, 0.005),\n",
    "    'clf__fit_intercept': (True, False),\n",
    "    'clf__n_iter': (10, 50, 85)\n",
    "}\n",
    "\n",
    "\n",
    "rf_grid_params = {\n",
    "    'vect__ngram_range': ((1,1),(1,2),(1,3)),\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__tokenizer': (simple_tokenizer, \n",
    "                        lemmas_tokenizer, \n",
    "                        lemmas_no_punct,\n",
    "                        lemmas_merge_np,\n",
    "                        lemmas_merge_ents,\n",
    "                        lemmas_merge_np_merge_ents\n",
    "                       ),\n",
    "    'clf__n_estimators': (10, 25),\n",
    "    'clf__criterion': ('gini', 'entropy'),\n",
    "    'clf__max_features': ('auto', None),\n",
    "    'clf__class_weight': (None, 'balanced')\n",
    "}\n",
    "\n",
    "svm_grid_params = {\n",
    "    'vect__ngram_range': ((1,1),(1,2),(1,3)),\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__tokenizer': (simple_tokenizer, lemmas_tokenizer, lemmas_no_punct),\n",
    "    'clf__C': (0.01, 0.1, 1, 10)#,\n",
    "#     'clf__max_iter': (1000, 2000)\n",
    "}\n",
    "\n",
    "svm_tokenization_grid_params = {\n",
    "    'vect__ngram_range': ((1,1),(1,2),(1,3)),\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__tokenizer': (simple_tokenizer,\n",
    "                        lemmas_tokenizer, \n",
    "                        lemmas_no_punct,\n",
    "                        lemmas_merge_np,\n",
    "                        lemmas_merge_ents,\n",
    "                        lemmas_merge_np_merge_ents\n",
    "                       ),\n",
    "    'clf__C': (0.01, 0.025, 0.05, 0.075)#,\n",
    "#     'clf__max_iter': (1000, 2000)\n",
    "}\n",
    "\n",
    "svm_sn_grid_params = {\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__tokenizer': (sn_tokenizer,\n",
    "                        sn_pos_tokenizer,\n",
    "                        sn_merge_ents,\n",
    "                        sn_pos_merge_ent,\n",
    "                        sn_merge_np\n",
    "                       ),\n",
    "    'clf__C': (0.04, 0.05)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "fmt = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "hndlr = logging.StreamHandler()\n",
    "hndlr.setFormatter(fmt)\n",
    "logger.addHandler(hndlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_grid(pipe, params, data, labels):\n",
    "    grid_search = GridSearchCV(pipe, params, n_jobs=-1, scoring=make_scorer(f1_weighted_scorer), cv=3, verbose=1)\n",
    "    \n",
    "    print \"Performing grid search...\"\n",
    "    print \"pipeline:\", [name for name, _ in pipe.steps]\n",
    "    print \"parameters:\"\n",
    "    pprint(params)\n",
    "    \n",
    "    t0 = time()\n",
    "    grid_search.fit(data, labels)\n",
    "    \n",
    "    print \"done in %0.3fs\" % (time() - t0)\n",
    "    print ''\n",
    "    \n",
    "    print \"Best score: %0.3f\" % grid_search.best_score_\n",
    "    print \"Best parameters set:\"\n",
    "    \n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(params.keys()):\n",
    "        print \"\\t%s: %r\" % (param_name, best_parameters[param_name])\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Except for the random forest, these are all linear classifiers of one form or another (I'm pretty sure that NB is linear for this case though I'd have to check) and they're all trying to find the best separating hyperplane in their own way.  As such, now that I've had a chance to play with the different models and see some of their perameters, I'm going to spend the rest of my time focusing on tokeniztion and feature transformations (tf-idf, etc.) using only MNB and LinearSVC using some of the hyperparameters I've found with these experiments.  I think that that is likely to give me the most bang for my buck as it were.\n",
    "\n",
    "### Try not nowercasing when using spacy tokenization\n",
    "\n",
    "### Findings:\n",
    "- Either brown clusters are really useless or I'm using them wrong\n",
    "- Merging entities consistently performs a tiny bit better than just lemmatization while merging noun chunks performs significantly worse.  \n",
    "    - I believe that this is most likely a quirk of the dataset\n",
    "- sn-grams (as described in the paper that I'll cite here are some point) perform consistently worse than just using ngrams\n",
    "- Still need to try spanning sngrams\n",
    "- For mnb, removing any tokens at all, even punctuation, hurts performance.  I'm not sure if that's a quirk of this data set or not though.\n",
    "\n",
    "##### Notes\n",
    "- It would be nice to have some way to visualize the outcomes of all of the classifiers tried in the grid searches but there are so many that it would be difficult\n",
    "  - I think a simple 2d list plot would actually work pretty well, as something like that should look like a kind of step function based on which parameter has changed each time.  The only thing is that it would be nice to get those steps highlighted or somthign so that I could say, I want to compare the outcomes of all classifiers that used this tokenizer, or somethign like that. I might be able to do that by just filtering the list tho. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the best config from each tokenizer\n",
    "tokenizers = mnb_tokenization_grid_params['vect__tokenizer']\n",
    "\n",
    "def t_filter(t):\n",
    "    def inner(score_tup):\n",
    "        return score_tup.parameters['vect__tokenizer'] == t\n",
    "    return inner\n",
    "\n",
    "def get_tokenizer_best(grid, tokenizers):\n",
    "    best = {}\n",
    "    \n",
    "    for tokenizer in tokenizers:\n",
    "        scores = filter(t_filter(tokenizer), grid.grid_scores_)\n",
    "        t_best = max(scores, key=lambda s: s.mean_validation_score)\n",
    "        best[tokenizer.func_name] = t_best.mean_validation_score\n",
    "    return best\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Is merging entities really doing anything?\n",
    "# Yes, but not actually all that much\n",
    "def get_vocab_sizes(params):\n",
    "    for t in params['vect__tokenizer']:\n",
    "        c = CountVectorizer(preprocessor=simple_cleaner,\n",
    "                             ngram_range=(1,3),\n",
    "                             tokenizer=t)\n",
    "        print t.func_name, len(c.fit(docs_list).vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.01, 0.1, 1, 10),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
      " 'vect__stop_words': ('english', None),\n",
      " 'vect__tokenizer': (<function simple_tokenizer at 0x7f5254df6848>,\n",
      "                     <function lemmas_tokenizer at 0x7f52783ee848>,\n",
      "                     <function lemmas_no_punct_tokenizer at 0x7f5254e21b18>)}\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 429.823s\n",
      "\n",
      "Best score: 0.579\n",
      "Best parameters set:\n",
      "\tclf__C: 0.1\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\tvect__stop_words: None\n",
      "\tvect__tokenizer: <function lemmas_tokenizer at 0x7f52783ee848>\n"
     ]
    }
   ],
   "source": [
    "svm_grid = process_grid(svm_pipe, svm_grid_params, docs_list, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.01, 0.025, 0.05, 0.075),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
      " 'vect__stop_words': ('english', None),\n",
      " 'vect__tokenizer': (<function simple_tokenizer at 0x7f8d7a1b1b18>,\n",
      "                     <function lemmas_tokenizer at 0x7f8d7a1b1cf8>,\n",
      "                     <function lemmas_no_punct at 0x7f8d7a1b1e60>,\n",
      "                     <function lemmas_merge_np at 0x7f8d7a1b1de8>,\n",
      "                     <function lemmas_merge_ents at 0x7f8d7a1b1f50>,\n",
      "                     <function lemmas_merge_np_merge_ents at 0x7f8de64c5de8>)}\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 432 out of 432 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1018.557s\n",
      "\n",
      "Best score: 0.583\n",
      "Best parameters set:\n",
      "\tclf__C: 0.05\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\tvect__stop_words: None\n",
      "\tvect__tokenizer: <function lemmas_tokenizer at 0x7f8d7a1b1cf8>\n"
     ]
    }
   ],
   "source": [
    "svm_tokenization_grid = process_grid(svm_pipe, svm_tokenization_grid_params, docs_list, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.04, 0.05),\n",
      " 'vect__stop_words': ('english', None),\n",
      " 'vect__tokenizer': (<function sn_tokenizer at 0x7f8de6409e60>,\n",
      "                     <function sn_pos_tokenizer at 0x7f8dd0fd1cf8>,\n",
      "                     <function sn_merge_ents at 0x7f8dd0fd11b8>,\n",
      "                     <function sn_pos_merge_ent at 0x7f8da38ff320>,\n",
      "                     <function sn_merge_np at 0x7f8da38ff410>)}\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 305.002s\n",
      "\n",
      "Best score: 0.567\n",
      "Best parameters set:\n",
      "\tclf__C: 0.04\n",
      "\tvect__stop_words: None\n",
      "\tvect__tokenizer: <function sn_merge_ents at 0x7f8dd0fd11b8>\n"
     ]
    }
   ],
   "source": [
    "svm_sn_grid = process_grid(svm_pipe, svm_sn_grid_params, docs_list, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNB Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most influential parameter (by far) is the alpha parameter for smoothing.\n",
    "The next most influential feature was the addition of n-grams, which made a big difference and also, using any kind of stopwords, even removing punctuation, seemed to have a very negative result on the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhmEYOeL/A5e9Fd7TrRgHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f524ebf5990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([clf.mean_validation_score for clf in mnb_grid.grid_scores_])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.001, 0.01, 0.1, 1),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
      " 'vect__stop_words': ('english', None),\n",
      " 'vect__tokenizer': (<function simple_tokenizer at 0x7f5254a35b90>,\n",
      "                     <function lemmas_tokenizer at 0x7f5254a35f50>,\n",
      "                     <function lemmas_no_punct_tokenizer at 0x7f5254a35ed8>)}\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 343.143s\n",
      "\n",
      "Best score: 0.634\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.1\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\tvect__stop_words: None\n",
      "\tvect__tokenizer: <function lemmas_tokenizer at 0x7f5254a35f50>\n"
     ]
    }
   ],
   "source": [
    "mnb_grid = process_grid(mnb_pipe, mnb_grid_params, docs_list, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNB Tokenization Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187355"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnb_grid.best_estimator_.steps[0][1].vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185133"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnb_tokenization_grid.best_estimator_.steps[0][1].vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.075, 0.1),\n",
      " 'vect__ngram_range': ((1, 1), (1, 3)),\n",
      " 'vect__stop_words': ('english', None),\n",
      " 'vect__tokenizer': (<function simple_tokenizer at 0x7f8da394caa0>,\n",
      "                     <function lemmas_tokenizer at 0x7f8da394c488>,\n",
      "                     <function lemmas_no_punct at 0x7f8da394c6e0>,\n",
      "                     <function lemmas_merge_np at 0x7f8da394ccf8>,\n",
      "                     <function lemmas_merge_ents at 0x7f8da394cd70>,\n",
      "                     <function lemmas_merge_np_merge_ents at 0x7f8da394c578>)}\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 354.367s\n",
      "\n",
      "Best score: 0.638\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.075\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\tvect__stop_words: None\n",
      "\tvect__tokenizer: <function lemmas_merge_ents at 0x7f8da394cd70>\n"
     ]
    }
   ],
   "source": [
    "mnb_tokenization_grid = process_grid(mnb_pipe, mnb_tokenization_grid_params, docs_list, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-ac02136bbb5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_tokenizer_best\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnb_tokenization_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnb_tokenization_grid_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vect__tokenizer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-82-715ecbdb5236>\u001b[0m in \u001b[0;36mget_tokenizer_best\u001b[1;34m(grid, tokenizers)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mt_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_validation_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mbest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_best\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_validation_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "get_tokenizer_best(mnb_tokenization_grid, mnb_tokenization_grid_params['vect__tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_tokenizer 214228\n",
      "lemmas_tokenizer 185133\n",
      "lemmas_no_punct 178210\n",
      "lemmas_merge_np 189509\n",
      "lemmas_merge_ents 185636\n",
      "lemmas_merge_np_merge_ents 189598\n"
     ]
    }
   ],
   "source": [
    "get_vocab_sizes(mnb_tokenization_grid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.075, 0.1),\n",
      " 'vect__ngram_range': ((1, 1), (1, 3)),\n",
      " 'vect__stop_words': ('english', None),\n",
      " 'vect__tokenizer': (<function lemmas_tokenizer at 0x7f8dd24bb5f0>,\n",
      "                     <function lemmas_no_punct at 0x7f8dd24bb578>,\n",
      "                     <function lemmas_merge_ents at 0x7f8dd24bb848>,\n",
      "                     <function brown_cluster_tokenizer at 0x7f8dd24bbaa0>,\n",
      "                     <function brown_cluster_merge_ents at 0x7f8dd2697a28>)}\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.7min\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 335.288s\n",
      "\n",
      "Best score: 0.638\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.075\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\tvect__stop_words: None\n",
      "\tvect__tokenizer: <function lemmas_merge_ents at 0x7f8dd24bb848>\n"
     ]
    }
   ],
   "source": [
    "mnb_brown_grid = process_grid(mnb_pipe, mnb_brown_grid_params, docs_list, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown_cluster_merge_ents': 0.040426216670964576,\n",
       " 'brown_cluster_tokenizer': 0.040426216670964576,\n",
       " 'lemmas_merge_ents': 0.63754580351976431,\n",
       " 'lemmas_no_punct': 0.62979803124252964,\n",
       " 'lemmas_tokenizer': 0.63706663132351105}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tokenizer_best(mnb_brown_grid, mnb_brown_grid_params['vect__tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmas_tokenizer 185133\n",
      "lemmas_no_punct 178210\n",
      "lemmas_merge_ents 185636\n",
      "brown_cluster_tokenizer 141\n",
      "brown_cluster_merge_ents 141\n"
     ]
    }
   ],
   "source": [
    "get_vocab_sizes(mnb_brown_grid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.075, 0.1),\n",
      " 'vect__stop_words': ('english', None),\n",
      " 'vect__tokenizer': (<function sn_tokenizer at 0x7f47844378c0>,\n",
      "                     <function sn_pos_tokenizer at 0x7f47e7ed1de8>,\n",
      "                     <function sn_merge_ents at 0x7f47e7ed1668>,\n",
      "                     <function sn_pos_merge_ent at 0x7f47e7ed1500>,\n",
      "                     <function sn_merge_np at 0x7f47e7ed1aa0>,\n",
      "                     <function sn_sr_tokenizer at 0x7f47e7ed1758>,\n",
      "                     <function sn_sr_merge_ent at 0x7f47e7ed17d0>,\n",
      "                     <function sn_spanning_tokenizer at 0x7f47e7ed1848>,\n",
      "                     <function sn_spanning_merge_ents at 0x7f478440b050>)}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-037fc15cfdcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmnb_sn_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnb_pipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnb_sn_grid_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-236058b7a184>\u001b[0m in \u001b[0;36mprocess_grid\u001b[1;34m(pipe, params, data, labels)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"done in %0.3fs\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 for train, test in cv)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    748\u001b[0m                 \u001b[1;31m# the results as we will raise the exception we got back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m                 \u001b[1;31m# to the caller instead of returning any result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_pool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m                     \u001b[1;31m# In case we had to terminate a managed pool, let\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_terminate_pool\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# terminate does a join()\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multiprocessing'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/pool.pyc\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/util.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, wr)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[0;32m    206\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[1;32m--> 207\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36m_terminate_pool\u001b[1;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'joining task handler'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m             \u001b[0mtask_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'joining result handler'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    958\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.join(): timed out\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    961\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    356\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                     \u001b[0mdelay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m                     \u001b[0m_sleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgotit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mnb_sn_grid = process_grid(mnb_pipe, mnb_sn_grid_params, docs_list, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sn_merge_ents': 0.59700803649875622,\n",
       " 'sn_merge_np': 0.56911889361623114,\n",
       " 'sn_pos_merge_ent': 0.23784061873661111,\n",
       " 'sn_pos_tokenizer': 0.23871240797297844,\n",
       " 'sn_sr_merge_ent': 0.21003203607692364,\n",
       " 'sn_sr_tokenizer': 0.21003203607692364,\n",
       " 'sn_tokenizer': 0.59366724307787844}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tokenizer_best(mnb_sn_grid, mnb_sn_grid_params['vect__tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sn_merge_ents': 0.59700803649875622,\n",
       " 'sn_merge_np': 0.56911889361623114,\n",
       " 'sn_pos_merge_ent': 0.23784061873661111,\n",
       " 'sn_pos_tokenizer': 0.23871240797297844,\n",
       " 'sn_tokenizer': 0.59366724307787844}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tokenizer_best(mnb_sn_grid, mnb_sn_grid_params['vect__tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__class_weight': (None, 'balanced'),\n",
      " 'clf__criterion': ('gini', 'entropy'),\n",
      " 'clf__max_features': ('auto', None),\n",
      " 'clf__n_estimators': (10, 25),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
      " 'vect__stop_words': ('english', None),\n",
      " 'vect__tokenizer': (<function simple_tokenizer at 0x7f8d7a1b1b18>,\n",
      "                     <function lemmas_tokenizer at 0x7f8d7a1b1cf8>,\n",
      "                     <function lemmas_no_punct at 0x7f8d7a1b1e60>,\n",
      "                     <function lemmas_merge_np at 0x7f8d7a1b1de8>,\n",
      "                     <function lemmas_merge_ents at 0x7f8d7a1b1f50>,\n",
      "                     <function lemmas_merge_np_merge_ents at 0x7f8de64c5de8>)}\n",
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 62.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 95.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 164.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed: 262.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 15776.134s\n",
      "\n",
      "Best score: 0.400\n",
      "Best parameters set:\n",
      "\tclf__class_weight: None\n",
      "\tclf__criterion: 'gini'\n",
      "\tclf__max_features: 'auto'\n",
      "\tclf__n_estimators: 25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "\tvect__tokenizer: <function lemmas_no_punct at 0x7f8d7a1b1e60>\n"
     ]
    }
   ],
   "source": [
    "rf_grid = process_grid(rf_pipe, rf_grid_params, docs_list, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.0001, 1e-05, 1e-06),\n",
      " 'clf__fit_intercept': (True, False),\n",
      " 'clf__l1_ratio': (0.15, 0.05, 0.005),\n",
      " 'clf__loss': ('hinge', 'log', 'perceptron'),\n",
      " 'clf__n_iter': (10, 50, 85),\n",
      " 'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
      " 'vect__stop_words': ('english', None),\n",
      " 'vect__tokenizer': (<function lemmas_tokenizer at 0x7f52783ee848>,\n",
      "                     <function lemmas_no_punct_tokenizer at 0x7f5254e21b18>)}\n",
      "Fitting 3 folds for each of 5832 candidates, totalling 17496 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 30.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 69.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 94.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 123.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 155.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 192.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 232.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 276.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 324.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 376.2min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed: 431.7min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 491.3min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 554.8min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 622.4min\n",
      "[Parallel(n_jobs=-1)]: Done 17496 out of 17496 | elapsed: 672.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 40381.515s\n",
      "\n",
      "Best score: 0.579\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.0001\n",
      "\tclf__fit_intercept: False\n",
      "\tclf__l1_ratio: 0.05\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__n_iter: 85\n",
      "\tclf__penalty: 'l2'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\tvect__stop_words: None\n",
      "\tvect__tokenizer: <function lemmas_no_punct_tokenizer at 0x7f5254e21b18>\n"
     ]
    }
   ],
   "source": [
    "sgd_grid = process_grid(sgd_pipe, sgd_grid_params, docs_list, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NGram Model\n",
    "This definitely isn't a BOW model, but everything is already loaded in this notebook so I wanted to test this here\n",
    "\n",
    "#### Findings:\n",
    "- Lemmas_merge_ents performed best, beating the basic lemmas_tokenizer by a slim margin exactly as it did got MNB.  I expected the lemmas_cased_merge_ents tokenizer to actually do better but nothing beats lemmas I guess.\n",
    "    - I'd like to try this again with some other data, but on this dataset it looks like lemmas plust merging entities wins again.\n",
    "\n",
    "\n",
    "#### Ideas:\n",
    "- Try without lowercase?\n",
    "    - The performance of the parser may be effected by casing so it might be better not to lowercase before tokenizing when using spacy\n",
    "- Try a lematizing tokenizer that resores original cases to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from candidate_classifier.nltk_model.ngram_classifier import NgramClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from candidate_classifier.tokenizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng_tokenizers = [TransformerABC(prefilter_substitutions=['strip'], \n",
    "                                tokenizer=t) for t in \n",
    "                 (simple_tokenizer,\n",
    "                  lemmas_tokenizer, \n",
    "                  lemmas_no_punct,\n",
    "                  lemmas_merge_np,\n",
    "                  lemmas_merge_ents,\n",
    "                  lemmas_merge_np_merge_ents,\n",
    "                  lemmas_cased_tokenizer,\n",
    "                  lemmas_cased_merge_ents\n",
    "                 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ng_data = [list(t(docs_list)) for t in ng_tokenizers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngram_pipe = Pipeline([\n",
    "        ('clf', OneVsOneClassifier(NgramClassifier(pad_ngrams=True)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51408072,  0.50890405,  0.51399413])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Tokenizer\n",
    "cross_val_score(ngram_pipe, np.asarray(ng_data[0]), y=labels_list, cv=3, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60340864,  0.59280579,  0.60896702])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmas Tokenizer\n",
    "# 0.60172715\n",
    "cross_val_score(ngram_pipe, np.asarray(ng_data[1]), y=labels_list, cv=3, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55570972,  0.53112549,  0.54334721])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmas no punct\n",
    "# 0.5433941399999999\n",
    "cross_val_score(ngram_pipe, np.asarray(ng_data[2]), y=labels_list, cv=3, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.57854247,  0.56107062,  0.57603022])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmas merge np\n",
    "# 0.5718811033333334\n",
    "cross_val_score(ngram_pipe, np.asarray(ng_data[3]), y=labels_list, cv=3, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60297723,  0.59464603,  0.61254024])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmas merge entities\n",
    "# 0.6033878333333333\n",
    "cross_val_score(ngram_pipe, np.asarray(ng_data[4]), y=labels_list, cv=3, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.57993891,  0.56202543,  0.57367771])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmas merge np and ents\n",
    "# 0.5718806833333333\n",
    "cross_val_score(ngram_pipe, np.asarray(ng_data[5]), y=labels_list, cv=3, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5987464 ,  0.58936852,  0.60117625])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmas cased\n",
    "# 0.59643039\n",
    "cross_val_score(ngram_pipe, np.asarray(ng_data[6]), y=labels_list, cv=3, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60078256,  0.58637938,  0.60122174])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmas Cased Merge Ents\n",
    "# 0.5961278933333333\n",
    "cross_val_score(ngram_pipe, np.asarray(ng_data[7]), y=labels_list, cv=3, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57520839  0.56867061  0.58508877]\n",
      "0.576322588505\n"
     ]
    }
   ],
   "source": [
    "# I have no idea what happened, I tried everything, even check out the old git version and nothing gets back \n",
    "# to that 60% f1 score.  :<\n",
    "# Lemmas merge entities\n",
    "scores = cross_val_score(ngram_pipe, np.asarray(ng_data[4]), y=labels_list, cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt = u\"What do you think Donald Trump has to say about that? Listening to this, do you think this is the tone  this immigration debate that republicans need to take to win back Hispanics into our party especially states like where we are in Nevada that has a pretty Hispanic community?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'702|WP|What  2042|VBP|do  602|PRP|you  1674|VB|think  502|NNP|Donald  22|NNP|Trump  890|VBZ|has  12|TO|to  1162|VB|say  618|IN|about  84|DT|that  0|.|?  510|VBG|Listening  12|IN|to  63|DT|this  4|,|,  2042|VBP|do  602|PRP|you  1674|VB|think  63|DT|this  762|VBZ|is  11|DT|the  2757|NN|tone  0|:|\\u2014  63|DT|this  55|NN|immigration  1733|NN|debate  84|WDT|that  0|VBZ|republicans  2954|VBP|need  12|TO|to  6666|VB|take  12|TO|to  1290|VB|win  7530|RP|back  1901|NNPS|Hispanics  8188|IN|into  59|PRP$|our  809|NN|party  27882|RB|especially  845|VBZ|states  1684|IN|like  8148|WRB|where  1626|PRP|we  1530|VBP|are  60|IN|in  166|NNP|Nevada  84|WDT|that  890|VBZ|has  19|DT|a  234|RB|pretty  215|JJ|Hispanic  1829|NN|community  0|.|?'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = nlp(txt)\n",
    "'  '.join(\"%s|%s|%s|%s\" % (tok.cluster, tok.tag_, tok.text) for tok in toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'what|True|What  do|False|do  you|False|you  think|False|think  Donald Trump|True|Donald Trump  have|False|has  to|False|to  say|False|say  about|False|about  that|False|that  ?|False|?  listen|True|Listening  to|False|to  this|False|this  ,|False|,  do|False|do  you|False|you  think|False|think  this|False|this  be|False|is  the|False|the  tone|False|tone  --|False|\\u2014  this|False|this  immigration|False|immigration  debate|False|debate  that|False|that  republicans|False|republicans  need|False|need  to|False|to  take|False|take  to|False|to  win|False|win  back|False|back  Hispanics|True|Hispanics  into|False|into  our|False|our  party|False|party  especially|False|especially  state|False|states  like|False|like  where|False|where  we|False|we  be|False|are  in|False|in  Nevada|True|Nevada  that|False|that  have|False|has  a|False|a  pretty|False|pretty  Hispanic|True|Hispanic  community|False|community  ?|False|?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = nlp(txt)\n",
    "for ent in toks.ents:\n",
    "    ent.merge(ent.root.tag_, ent.text, ent.label_)\n",
    "'  '.join(\"%s|%s|%s\" % (tok.lemma_, tok.is_title, tok.text) for tok in toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'spacy.tokens.span.Span'>\n",
      "<type 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "for sent in nlp(txt).sents:\n",
    "    print type(sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Best, New York, Saturday morning]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nlp(u'Mr. Best flew to New York on Saturday morning.')\n",
    "ents = list(tokens.ents)\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"we 're close too many hospital .\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = u\"We're closing too many hospitals.\"\n",
    "' '.join(tok.lemma_ for tok in nlp(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news\n",
      "effect\n"
     ]
    }
   ],
   "source": [
    "txt = u\"Economic news has little effect on financial markets\"\n",
    "for s in nlp(txt).sents:\n",
    "    for c in s.root.children:\n",
    "        print c.orth_\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True|Economic  False|news  False|has  False|little  False|effect  False|on  False|financial  False|markets\n",
      "[False, False, True, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "txt = u\"Economic news has little effect on financial markets\"\n",
    "print '  '.join(\"%s|%s\" % (tok.is_title, tok.text) for tok in nlp(txt))\n",
    "print [tok.dep_ == 'ROOT' for tok in nlp(txt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic Ngrams\n",
    "ngrams based on the neighbors in the dependency tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get paths that cross head-nodes\n",
    "\n",
    "\n",
    "def sn_grams(sent, m, n, prop='lemma_', spanning=False):\n",
    "    \"\"\"Get all syntactic ngrams from min length m to max length n\"\"\"\n",
    "    root = sent.root\n",
    "    if spanning:\n",
    "        return sn_spanning_helper([], deque([], n), root, m, prop=prop)\n",
    "    else:\n",
    "        return sn_helper([], deque([], n), root, m, prop=prop)\n",
    "\n",
    "def sn_helper(acc, buff, curr, m, prop='lemma_'):\n",
    "    # Add curr\n",
    "    # But don't add ROOT because those relations occur in almost all sentences\n",
    "    # NB: No need to pop b/c deque has max length specified\n",
    "    if prop == 'dep_' and curr.dep_ == 'ROOT':\n",
    "        pass\n",
    "    else:\n",
    "        buff.appendleft(getattr(curr, prop))\n",
    "    \n",
    "    # Create the ngrams that end with the current node\n",
    "    # Having the n-grams in reverse lexical order is a bit odd \n",
    "    # for humans to read, but because it's deterministic, it \n",
    "    # shouldn't make any difference to the computer for using them as \n",
    "    # features\n",
    "    gram = []\n",
    "    if len(buff) >= m:\n",
    "        for i, tok in enumerate(buff):\n",
    "            # Build up the ngram\n",
    "            gram.append(tok)\n",
    "            # Only append ngrams >= the min length\n",
    "            if len(gram) >= m:\n",
    "                acc.append('_'.join(reversed(gram)))\n",
    "    \n",
    "    # Optimized\n",
    "#     gram = ''\n",
    "#     count = 0\n",
    "#     if len(buff) >= m:\n",
    "#         for i, tok in enumerate(buff):\n",
    "#             # Build up the ngram\n",
    "#             gram += '_' + tok\n",
    "#             count += 1\n",
    "#             # Only append ngrams >= the min length\n",
    "#             if count >= m:\n",
    "#                 acc.append(gram)\n",
    "    \n",
    "    # Add all childrens' ngrams\n",
    "    for c in curr.children:\n",
    "        # Add to acc with destructive modification \n",
    "        # but don't let children modify buffer because it needs \n",
    "        # to be in the same state for the next child of curr\n",
    "        sn_helper(acc, copy.copy(buff), c, m, prop=prop)\n",
    "    \n",
    "    # Return the accumulator\n",
    "    return acc\n",
    "        \n",
    "\n",
    "    \n",
    "def sn_spanning_helper(acc, buff, curr, m, prop='lemma_'):\n",
    "    # Add curr\n",
    "    # But don't add ROOT because those relations occur in almost all sentences\n",
    "    # NB: No need to pop b/c deque has max length specified\n",
    "    if prop == 'dep_' and curr.dep_ == 'ROOT':\n",
    "        pass\n",
    "    else:\n",
    "        buff.appendleft(getattr(curr, prop))\n",
    "    \n",
    "    # Create the ngrams that end with the current node\n",
    "    # Having the n-grams in reverse lexical order is a bit odd \n",
    "    # for humans to read, but because it's deterministic, it \n",
    "    # shouldn't make any difference to the computer for using them as \n",
    "    # features\n",
    "    gram = []\n",
    "    if len(buff) >= m:\n",
    "        for i, tok in enumerate(buff):\n",
    "            # Build up the ngram\n",
    "            gram.append(tok)\n",
    "            # Only append ngrams >= the min length\n",
    "            if len(gram) >= m:\n",
    "                acc.append('_'.join(reversed(gram)))\n",
    "    \n",
    "    # Add all left ngrams\n",
    "    for c in curr.lefts:\n",
    "        # Add to acc with destructive modification \n",
    "        # but don't let children modify buffer because it needs \n",
    "        # to be in the same state for the next child of curr\n",
    "        sn_spanning_helper(acc, copy.copy(buff), c, m, prop=prop)\n",
    "    \n",
    "    # Now, decend the parent's rights\n",
    "    # So long as this isn't the root\n",
    "    if curr.dep_ != 'ROOT':\n",
    "        for c in curr.head.rights:\n",
    "            sn_spanning_helper(acc, copy.copy(buff), c, m, prop=prop)\n",
    "    \n",
    "    # Return the accumulator\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected = [u'have_news', u'news_economic', u'have_effect', u'effect_little', u'effect_on', \n",
    "            u'on_markets', u'markets_financial']\n",
    "txt = u\"Economic news have little effect on financial markets\"\n",
    "\n",
    "for s in nlp(txt).sents:\n",
    "    print sn_grams(s, 1, 2, prop='lower_', spanning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([u'have'], maxlen=2)\n",
      "deque([u'news', u'have'], maxlen=2)\n",
      "deque([u'economic', u'news'], maxlen=2)\n",
      "deque([u'effect', u'have'], maxlen=2)\n",
      "deque([u'little', u'effect'], maxlen=2)\n",
      "deque([u'on', u'effect'], maxlen=2)\n",
      "deque([u'markets', u'on'], maxlen=2)\n",
      "deque([u'financial', u'markets'], maxlen=2)\n",
      "[u'have', u'news', u'have_news', u'economic', u'news_economic', u'effect', u'have_effect', u'little', u'effect_little', u'on', u'effect_on', u'markets', u'on_markets', u'financial', u'markets_financial']\n"
     ]
    }
   ],
   "source": [
    "expected = [u'have_news', u'news_economic', u'have_effect', u'effect_little', u'effect_on', \n",
    "            u'on_markets', u'markets_financial']\n",
    "txt = u\"Economic news have little effect on financial markets\"\n",
    "\n",
    "for s in nlp(txt).sents:\n",
    "    print sn_grams(s, 1, 2, prop='lower_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g ['d']\n",
      "a ['d']\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "buff = ['a', 'b', 'c', 'd']\n",
    "gram = []\n",
    "for i in xrange(len(buff)-1, len(buff)-(1+1), -1):\n",
    "    gram.append(buff[i])\n",
    "    print 'g',gram\n",
    "    acc.append('_'.join(reversed(gram)))\n",
    "    print 'a', acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    }
   ],
   "source": [
    "txt = u'On evening tides, we ride.'\n",
    "toks = nlp(txt)\n",
    "print toks[0].n_rights, toks[0].n_lefts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bushy = dcr.grouped_sents(speakers=candidates)['BUSH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.ConcatenatedCorpusView'>\n",
      "True\n",
      "[u\"Absolutely, I do, and I'm gonna run hard, run with heart, and run to win. \", u\"I'm gonna have to earn this. \", ...]\n"
     ]
    }
   ],
   "source": [
    "from collections import Iterable\n",
    "import collections\n",
    "from types import *\n",
    "print type(bushy)\n",
    "print issubclass(bushy[0].__class__, Iterable)\n",
    "print bushy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bushy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    for i in xrange(10):\n",
    "        yield i\n",
    "f = foo()\n",
    "print issubclass(f, Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Foo(object):\n",
    "    def __private(self):\n",
    "        print \"foo!\"\n",
    "        \n",
    "class Bar(Foo):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance('abc', collections.Iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(bushy, Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(itertools.ifilter(None, [1,2,3]), GeneratorType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(f, collections.Iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
