{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from spacy.en import English\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/Storage/Coding_Projects/Candidate_Classifier'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/Storage/Coding_Projects/Candidate_Classifier'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from candidate_classifier.string_processing import *\n",
    "from candidate_classifier.nltk_model.ngram_classifier import NgramClassifierMulti\n",
    "from candidate_classifier.tokenizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import make_scorer, classification_report, f1_score\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import codecs\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "from candidate_classifier.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.dev0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "fmt = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "hndlr = logging.StreamHandler()\n",
    "hndlr.setFormatter(fmt)\n",
    "logger.addHandler(hndlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nlp = English(load_vectors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents_path = 'candidate_classifier/data/processed/clean_sents.txt'\n",
    "labels_path = 'candidate_classifier/data/processed/sent_labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'BUSH', u'CARSON', u'CHRISTIE', u'CLINTON', u'CRUZ', u'KASICH', u'RUBIO', u'SANDERS', u'TRUMP']\n"
     ]
    }
   ],
   "source": [
    "def docs():\n",
    "    with codecs.open(sents_path, mode='r', encoding='utf-8') as _f:\n",
    "        for line in _f:\n",
    "            yield line\n",
    "\n",
    "def labels():\n",
    "    with codecs.open(labels_path, mode='r', encoding='utf-8') as _f:\n",
    "        for line in _f:\n",
    "            yield line.strip()\n",
    "labels_list = list(labels())\n",
    "candidates = sorted(list(set(labels_list)))\n",
    "docs_list = list(docs())\n",
    "print candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(clf, X, y):\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring='f1_samples')\n",
    "    print scores\n",
    "    print \"\\n\"\n",
    "    # Use 1.96 * std b/c 95% of the data should lie in that range, \n",
    "    # which means this represents a 95% confidence interval\n",
    "    print \"F1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 1.960)\n",
    "    \n",
    "def fancy_scorer(y, y_pred, **kwargs):\n",
    "    # Print classification report\n",
    "    print classification_report(y, y_pred, target_names=candidates)\n",
    "    return f1_score(y, y_pred, labels=candidates, average='weighted')    \n",
    "\n",
    "def f1_weighted_scorer(y, y_pred, **kwargs):\n",
    "    return f1_score(y, y_pred, labels=candidates, average='weighted')\n",
    "\n",
    "# Decorator to get averages from cross-validation\n",
    "def avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_grid(pipe, params, data, labels):\n",
    "    grid_search = GridSearchCV(pipe, params, n_jobs=1, scoring=make_scorer(f1_weighted_scorer), cv=3, verbose=1)\n",
    "    \n",
    "    print \"Performing grid search...\"\n",
    "    print \"pipeline:\", [name for name, _ in pipe.steps]\n",
    "    print \"parameters:\"\n",
    "    pprint(params)\n",
    "    \n",
    "    t0 = time()\n",
    "    grid_search.fit(data, labels)\n",
    "    \n",
    "    print \"done in %0.3fs\" % (time() - t0)\n",
    "    print ''\n",
    "    \n",
    "    print \"Best score: %0.3f\" % grid_search.best_score_\n",
    "    print \"Best parameters set:\"\n",
    "    \n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(params.keys()):\n",
    "        print \"\\t%s: %r\" % (param_name, best_parameters[param_name])\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "- Should create a validation set before tuning\n",
    "\n",
    "- Data is tokenized and pre-processed ahead of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_transformer = TransformerABC(prefilter_substitutions=['strip'], tokenizer=lemmas_merge_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = list(s_transformer(docs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'CARDINAL                                     '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(t.ent_type_ for t in nlp(docs_list[5001]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noop = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnb_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=noop, \n",
    "                                 lowercase=True, \n",
    "                                 ngram_range=(1,3),\n",
    "                                 token_pattern=r\".*\", \n",
    "                                 tokenizer=noop)),\n",
    "        ('clf', MultinomialNB(alpha=0.075))\n",
    "])\n",
    "\n",
    "mnb_calibrated_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=noop, \n",
    "                                 lowercase=True, \n",
    "                                 ngram_range=(1,3),\n",
    "                                 token_pattern=r\".*\", \n",
    "                                 tokenizer=noop)),\n",
    "        ('clf', CalibratedClassifierCV(MultinomialNB(alpha=0.075), method='sigmoid', cv=10))\n",
    "])\n",
    "\n",
    "mnb_iso_calibrated_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=noop, \n",
    "                                 lowercase=True, \n",
    "                                 ngram_range=(1,3),\n",
    "                                 token_pattern=r\".*\", \n",
    "                                 tokenizer=noop)),\n",
    "        ('clf', CalibratedClassifierCV(MultinomialNB(alpha=0.075), method='isotonic', cv=10))\n",
    "])\n",
    "\n",
    "ng_pipe = Pipeline([\n",
    "        ('clf', NgramClassifierMulti(pad_ngrams=True))\n",
    "])\n",
    "\n",
    "ng_calibrated_pipe = Pipeline([\n",
    "        ('clf', CalibratedClassifierCV(NgramClassifierMulti(pad_ngrams=True), method='sigmoid', cv=5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('mnb', mnb_pipe),\n",
    "                                    ('ngram', ng_pipe)],\n",
    "                        voting='soft')\n",
    "\n",
    "e_pipe = Pipeline([('eclf', eclf)])\n",
    "\n",
    "eclf_calibrated = VotingClassifier(estimators=[('mnb', mnb_calibrated_pipe),\n",
    "                                               ('ngram', ng_calibrated_pipe)],\n",
    "                                   voting='soft')\n",
    "\n",
    "e_calibrated_pipe = Pipeline([('eclf', eclf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_grid_params = {\n",
    "    'eclf__weights': [p for p in itertools.permutations([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble \n",
    "Even after using a grid search to find optimal weights the performance of the ensemble was very poor compared to each classifier one it's own.  \n",
    "- *Ensemble*: 0.527\n",
    "- MNB: 0.638\n",
    "- Ngram: 0.603\n",
    "\n",
    "I think that the reason for this is that the voting classifier uses the predicted probabilities `predict_proba` instead of using the actual predictions and both MNB and the ngram classifier are terrible at predicting the probability of a class given a sample, even though they're very good a predicting the actual class.  There's even a warning about this in the sklearn User Guide.  \n",
    "\n",
    "The Ngram classifier isn't actually all that terrible as predicing the probabilities, it's just a very different kind of calculation and model.\n",
    "\n",
    "To combat this, I thought I'd try a new class/feature that is only available in scikit-learn 18.0 (installed from master on github).  This class uses some held-out data to tune the output of `predict_proba`.\n",
    "\n",
    "#### Attempt 2\n",
    "After debugging the predict_proba method in the NgramClassifierMulti I tried again, as well as re-running MNB and Ngram separately (I suspect that lowercaing before entity detection may have actually boosted performance in the other tests for some reason) I got this:\n",
    "- MNB: 0.636\n",
    "- Ngram: \n",
    "- Ensemble: 0.636\n",
    "- Calibrated Ensemble: 0.636\n",
    "\n",
    "Both calibrated and uncalibrated ensembles are identical in performance to MNB by itself.  And I'm not entirely sure what to do about it now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncalibrated Ensemble\n",
    "Unfortunately, even after a 5 hour grid-search for optimal weights for the two classifiers, the ensemble performed terribly compared to the individual classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['eclf']\n",
      "parameters:\n",
      "{'eclf__weights': [(0.1, 0.2),\n",
      "                   (0.1, 0.3),\n",
      "                   (0.1, 0.4),\n",
      "                   (0.1, 0.5),\n",
      "                   (0.1, 0.6),\n",
      "                   (0.1, 0.7),\n",
      "                   (0.1, 0.8),\n",
      "                   (0.1, 0.9),\n",
      "                   (0.1, 1.0),\n",
      "                   (0.2, 0.1),\n",
      "                   (0.2, 0.3),\n",
      "                   (0.2, 0.4),\n",
      "                   (0.2, 0.5),\n",
      "                   (0.2, 0.6),\n",
      "                   (0.2, 0.7),\n",
      "                   (0.2, 0.8),\n",
      "                   (0.2, 0.9),\n",
      "                   (0.2, 1.0),\n",
      "                   (0.3, 0.1),\n",
      "                   (0.3, 0.2),\n",
      "                   (0.3, 0.4),\n",
      "                   (0.3, 0.5),\n",
      "                   (0.3, 0.6),\n",
      "                   (0.3, 0.7),\n",
      "                   (0.3, 0.8),\n",
      "                   (0.3, 0.9),\n",
      "                   (0.3, 1.0),\n",
      "                   (0.4, 0.1),\n",
      "                   (0.4, 0.2),\n",
      "                   (0.4, 0.3),\n",
      "                   (0.4, 0.5),\n",
      "                   (0.4, 0.6),\n",
      "                   (0.4, 0.7),\n",
      "                   (0.4, 0.8),\n",
      "                   (0.4, 0.9),\n",
      "                   (0.4, 1.0),\n",
      "                   (0.5, 0.1),\n",
      "                   (0.5, 0.2),\n",
      "                   (0.5, 0.3),\n",
      "                   (0.5, 0.4),\n",
      "                   (0.5, 0.6),\n",
      "                   (0.5, 0.7),\n",
      "                   (0.5, 0.8),\n",
      "                   (0.5, 0.9),\n",
      "                   (0.5, 1.0),\n",
      "                   (0.6, 0.1),\n",
      "                   (0.6, 0.2),\n",
      "                   (0.6, 0.3),\n",
      "                   (0.6, 0.4),\n",
      "                   (0.6, 0.5),\n",
      "                   (0.6, 0.7),\n",
      "                   (0.6, 0.8),\n",
      "                   (0.6, 0.9),\n",
      "                   (0.6, 1.0),\n",
      "                   (0.7, 0.1),\n",
      "                   (0.7, 0.2),\n",
      "                   (0.7, 0.3),\n",
      "                   (0.7, 0.4),\n",
      "                   (0.7, 0.5),\n",
      "                   (0.7, 0.6),\n",
      "                   (0.7, 0.8),\n",
      "                   (0.7, 0.9),\n",
      "                   (0.7, 1.0),\n",
      "                   (0.8, 0.1),\n",
      "                   (0.8, 0.2),\n",
      "                   (0.8, 0.3),\n",
      "                   (0.8, 0.4),\n",
      "                   (0.8, 0.5),\n",
      "                   (0.8, 0.6),\n",
      "                   (0.8, 0.7),\n",
      "                   (0.8, 0.9),\n",
      "                   (0.8, 1.0),\n",
      "                   (0.9, 0.1),\n",
      "                   (0.9, 0.2),\n",
      "                   (0.9, 0.3),\n",
      "                   (0.9, 0.4),\n",
      "                   (0.9, 0.5),\n",
      "                   (0.9, 0.6),\n",
      "                   (0.9, 0.7),\n",
      "                   (0.9, 0.8),\n",
      "                   (0.9, 1.0),\n",
      "                   (1.0, 0.1),\n",
      "                   (1.0, 0.2),\n",
      "                   (1.0, 0.3),\n",
      "                   (1.0, 0.4),\n",
      "                   (1.0, 0.5),\n",
      "                   (1.0, 0.6),\n",
      "                   (1.0, 0.7),\n",
      "                   (1.0, 0.8),\n",
      "                   (1.0, 0.9)]}\n",
      "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed: 55.0min\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed: 221.4min\n",
      "[Parallel(n_jobs=1)]: Done 270 out of 270 | elapsed: 300.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 18056.854s\n",
      "\n",
      "Best score: 0.527\n",
      "Best parameters set:\n",
      "\teclf__weights: (0.1, 0.2)\n"
     ]
    }
   ],
   "source": [
    "# Best score: 0.527\n",
    "# Best parameters set:\n",
    "#    eclf__weights: (0.1, 0.2)\n",
    "eclf_grid = process_grid(e_pipe, e_grid_params, np.asarray(data), labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6347393 ,  0.62871688,  0.64536225])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.63627281\n",
    "cross_val_score(e_pipe, np.asarray(data), y=np.asarray(labels_list), cv=3, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63627281"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ 0.6347393 ,  0.62871688,  0.64536225])/3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble of Calibrated Classifiers\n",
    "Parameters to try and tune:\n",
    "- Calibration cv proportion\n",
    "- Calibration method\n",
    "- Voting weights\n",
    "\n",
    "If I do this single-threaded it's going to take days.  So before moving any further, I need to get the NgramClassifier to be pickleable so that training can be paralellized.  \n",
    "\n",
    "#### Notes:\n",
    "- I'm wondering if the Calibration is actually overpowering the ngram model predictions because the probabilities are so small.\n",
    "    - Maybe try normalizing them agian?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6347393 ,  0.62871688,  0.64536225])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.63627281\n",
    "scores = cross_val_score(e_calibrated_pipe, np.asarray(data), y=np.asarray(labels_list), cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63627281"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ 0.6347393 ,  0.62871688,  0.64536225])/3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram Classifier\n",
    "I didn't go and do full testing for this as it's very slow, but I'm going to go with sigmoid calibration and cv=5 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5755364   0.56865313  0.58511841]\n",
      "0.576435981044\n"
     ]
    }
   ],
   "source": [
    "ng_clf = NgramClassifierMulti(pad_ngrams=True)\n",
    "scores = cross_val_score(ng_clf, np.asarray(data), y=np.asarray(labels_list), cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.56352883,  0.55589307,  0.56753999])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.51829223 | cv 2\n",
    "# 0.56232063 | cv 5\n",
    "ng_sig_calibrated = CalibratedClassifierCV(NgramClassifierMulti(pad_ngrams=True), method='sigmoid', cv=5)\n",
    "cross_val_score(ng_sig_calibrated, np.asarray(data), y=np.asarray(labels_list), cv=3, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50647047"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ 0.5055898 ,  0.49214416,  0.52167745])/3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5055898 ,  0.49214416,  0.52167745])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.50647047  | cv 2\n",
    "ng_iso_calibrated = CalibratedClassifierCV(NgramClassifierMulti(pad_ngrams=True), method='isotonic', cv=5)\n",
    "scores = cross_val_score(ng_iso_calibrated, np.asarray(data), y=np.asarray(labels_list), cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much difference does the calibration actually make?\n",
    "It looks like it makes a HUGE difference.  About 100 orders of magnitude.  And the relative sizes change too which is interesting.  That must be a broduct of the training as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NgramClassifierMulti(alpha=0.01, n=4, pad_ngrams=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No calibration\n",
    "ng_clf = NgramClassifierMulti(pad_ngrams=True)\n",
    "ng_clf.fit(np.asarray(data[:5000]), y=np.asarray(labels_list[:5000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.2641113e-97,  8.7620716e-91,  3.6653292e-108,  2.12166e-100,\n",
       "         1.8747944e-102,  2.5529805e-95,  3.7461873e-93,  3.7618544e-98,\n",
       "         4.8920979e-94]], dtype=float128)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_clf.predict_proba(np.asarray([data[5001]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=NgramClassifierMulti(alpha=0.01, n=4, pad_ngrams=True),\n",
       "            cv=5, method='sigmoid')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sigmoid calibration\n",
    "ng_sig_calibrated = CalibratedClassifierCV(NgramClassifierMulti(pad_ngrams=True), method='sigmoid', cv=5)\n",
    "ng_sig_calibrated.fit(np.asarray(data[:5000]), y=np.asarray(labels_list[:5000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03016343,  0.2648251 ,  0.0078094 ,  0.01818411,  0.00965148,\n",
       "         0.11937918,  0.22514597,  0.05931179,  0.26552953]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_sig_calibrated.predict_proba(np.asarray([data[5001]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Isotonic Calibration\n",
    "ng_iso_calibrated = CalibratedClassifierCV(NgramClassifierMulti(pad_ngrams=True), method='isotonic', cv=5)\n",
    "ng_iso_calibrated.fit(np.asarray(data[:5000]), y=np.asarray(labels_list[:5000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng_iso_calibrated.predict_proba(np.asarray(data[5001:5011]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'SANDERS'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_list[5001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'One',\n",
       " u'candidate',\n",
       " u'say',\n",
       " u',',\n",
       " u'you',\n",
       " u'know',\n",
       " u'what',\n",
       " u',',\n",
       " u'i',\n",
       " u'do',\n",
       " u'not',\n",
       " u'think',\n",
       " u'it',\n",
       " u\"'\",\n",
       " u'a',\n",
       " u'great',\n",
       " u'idea',\n",
       " u'that',\n",
       " u'we',\n",
       " u'sell',\n",
       " u'automatic',\n",
       " u'weapon',\n",
       " u'in',\n",
       " u'this',\n",
       " u'country',\n",
       " u'that',\n",
       " u'be',\n",
       " u'use',\n",
       " u'by',\n",
       " u'the',\n",
       " u'military',\n",
       " u'to',\n",
       " u'kill',\n",
       " u'people',\n",
       " u'very',\n",
       " u'rapidly',\n",
       " u'.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[5001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.62153317e-16,   9.91291701e-12,   5.59500722e-23,\n",
       "          5.63048562e-18,   3.68156402e-24,   7.30748436e-04,\n",
       "          2.69235845e-08,   1.16932402e-07,   9.99269108e-01]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf.predict_proba([data[5001]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNB\n",
    "As far as I can tell, the calibration isn't really helping with the predictions of MNB.  I'm assuming that's because tuning the estimated probabilities doesn't really impact the predictions and all that's happening here is that the classifier has less data to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6347393   0.62871688  0.64536225]\n",
      "0.636272811277\n"
     ]
    }
   ],
   "source": [
    "# no calibration\n",
    "# 0.636272811277\n",
    "scores = cross_val_score(mnb_pipe, np.asarray(data), y=labels_list, cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.66328298  0.64550859  0.65134172  0.65005093  0.68389557  0.66615237\n",
      "  0.63893501  0.6602161   0.67554382  0.66410054]\n",
      "0.659902762496\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid calibration\n",
    "# score          | Calibration cv\n",
    "# 0.58836935204  | cv 2\n",
    "# 0.656218712521 | cv 4\n",
    "# 0.656513250898 | cv 5\n",
    "# 0.659902762496 | cv 10\n",
    "scores = cross_val_score(mnb_calibrated_pipe, np.asarray(data), y=labels_list, cv=10, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64189394  0.62043737  0.63846839  0.64250606  0.67504492  0.65079924\n",
      "  0.62704031  0.64975024  0.66868239  0.65248642]\n",
      "0.646710928805\n"
     ]
    }
   ],
   "source": [
    "# Isotonic calibration\n",
    "# score          | Calibration cv\n",
    "# 0.625965743338 | cv 2\n",
    "# 0.649969046504 | cv 4\n",
    "# 0.648737116078 | cv 5\n",
    "# 0.646710928805 | cv 10\n",
    "scores = cross_val_score(mnb_iso_calibrated_pipe, np.asarray(data), y=labels_list, cv=10, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Now much difference is calibration making in the outputs?\n",
    "It looks very similar to ngram calibrated.  It's normalized and there's definitely a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3),\n",
       "        preprocessor=<function <lambda> at 0x7...5f266500>, vocabulary=None)), ('clf', MultinomialNB(alpha=0.075, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=noop, \n",
    "                                 lowercase=True, \n",
    "                                 ngram_range=(1,3),\n",
    "                                 token_pattern=r\".*\", \n",
    "                                 tokenizer=noop)),\n",
    "        ('clf', MultinomialNB(alpha=0.075))\n",
    "])\n",
    "mnb_clf.fit(np.asarray(data[:5000]), y=labels_list[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.62153317e-16,   9.91291701e-12,   5.59500722e-23,\n",
       "          5.63048562e-18,   3.68156402e-24,   7.30748436e-04,\n",
       "          2.69235845e-08,   1.16932402e-07,   9.99269108e-01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf.predict_proba([data[5001]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3),\n",
       "        preprocessor=<function <lambda> at 0x7...=MultinomialNB(alpha=0.075, class_prior=None, fit_prior=True),\n",
       "            cv=5, method='sigmoid'))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_cal = Pipeline([\n",
    "        ('vect', CountVectorizer(preprocessor=noop, \n",
    "                                 lowercase=True, \n",
    "                                 ngram_range=(1,3),\n",
    "                                 token_pattern=r\".*\", \n",
    "                                 tokenizer=noop)),\n",
    "        ('clf', CalibratedClassifierCV(MultinomialNB(alpha=0.075), method='sigmoid', cv=5))\n",
    "])\n",
    "mnb_cal.fit(np.asarray(data[:5000]), y=np.asarray(labels_list[:5000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04600529,  0.03726734,  0.03414099,  0.08494592,  0.06160214,\n",
       "         0.09824496,  0.08294551,  0.0630373 ,  0.49181055]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_cal.predict_proba([data[5001]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngm = NgramClassifierMulti(pad_ngrams=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NgramClassifierMulti(alpha=0.01, n=4, pad_ngrams=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngm.fit(np.asarray(data[:1000]), labels_list[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'TRUMP'], \n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngm.predict([[\"I\", \"know\", 'these', 'people', '.']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.59896116e-30,   7.29195013e-24,   1.21394829e-24,\n",
       "          1.09368510e-25,   2.22115853e-30,   3.58526733e-30,\n",
       "          2.05846351e-25,   1.24726343e-25,   4.70065852e-23]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngm.predict_proba(np.asarray([[\"I\", \"know\", 'these', 'people', '.']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 97.45653483,  76.85996958,  79.4465673 ,  82.91900496,\n",
       "         98.50653048,  97.81576215,  82.0066345 ,  82.72943617,  74.1714833 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log2(ngm.predict_proba(np.asarray([[\"I\", \"know\", 'these', 'people', '.']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3),\n",
       "        preprocessor=<function <lambda> at 0x...fe55878c0>, vocabulary=None)), ('clf', MultinomialNB(alpha=0.75, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mnb_pipe.fit(np.asarray(data[:1000]), labels_list[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00298788,  0.02707586,  0.0074726 ,  0.03757738,  0.00335146,\n",
       "         0.01125558,  0.02626028,  0.07577926,  0.80823969]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_pipe.predict_proba(np.asarray([[\"I\", \"know\", 'these', 'people', '.']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.81319012,  3.60911254,  4.89651188,  3.2813531 ,  5.69835901,\n",
       "         4.48689127,  3.63969773,  2.57993067,  0.21289661]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(mnb_pipe.predict_proba(np.asarray([[\"I\", \"know\", 'these', 'people', '.']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vect',\n",
       "  CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 3),\n",
       "          preprocessor=<function <lambda> at 0x7f4fe55878c0>,\n",
       "          stop_words=None, strip_accents=None, token_pattern='.*',\n",
       "          tokenizer=<function <lambda> at 0x7f4fe55878c0>, vocabulary=None)),\n",
       " ('clf', MultinomialNB(alpha=0.75, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-55.07560706, -52.87152948, -54.15892882, -52.54377004,\n",
       "        -54.96077594, -53.7493082 , -52.90211467, -51.84234761,\n",
       "        -49.47531355]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_v = mnb_pipe.steps[0][1]\n",
    "mnb_clf = mnb_pipe.steps[1][1]\n",
    "\n",
    "mnb_clf._joint_log_likelihood(mnb_v.transform(np.asarray([[\"I\", \"know\", 'these', 'people', '.']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-49.26241694])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jll = mnb_clf._joint_log_likelihood(mnb_v.transform(np.asarray([[\"I\", \"know\", 'these', 'people', '.']])))\n",
    "logsumexp(jll, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-55.07560706, -52.87152948, -54.15892882, -52.54377004,\n",
       "        -54.96077594, -53.7493082 , -52.90211467, -51.84234761,\n",
       "        -49.47531355]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.81319012, -3.60911254, -4.89651188, -3.2813531 , -5.69835901,\n",
       "        -4.48689127, -3.63969773, -2.57993067, -0.21289661]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jll - np.atleast_2d(logsumexp(jll, axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-49.26241694]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.atleast_2d(logsumexp(jll, axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.81319012, -3.60911254, -4.89651188, -3.2813531 , -5.69835901,\n",
       "        -4.48689127, -3.63969773, -2.57993067, -0.21289661]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jll - logsumexp(jll, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,j) for i in range(4) for j in range(i+1, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.asarray(data[1001:1011])\n",
    "idxs = [(i,j) for i in range(9) for j in range(i+1, 9)]\n",
    "confidences = [est.predict_proba(X) for est in ngm.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidences[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 9, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = np.zeros((len(ngm.estimators_), len(ngm.classes_), 10))\n",
    "\n",
    "for i, c in enumerate(confidences):\n",
    "    tup = idxs[i]\n",
    "    for j, col in enumerate(tup):\n",
    "        probs[i, col, :] = c[:, j]\n",
    "        \n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.mean(axis=0).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1, 0, 1, 0],\n",
       "        [0, 1, 0, 1]],\n",
       "\n",
       "       [[0, 1, 0, 1],\n",
       "        [1, 0, 1, 0]],\n",
       "\n",
       "       [[1, 0, 1, 0],\n",
       "        [0, 1, 0, 1]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([[[1,0,1,0], [0,1,0,1]], [[0,1,0,1],[1,0,1,0]], [[1,0,1,0], [0,1,0,1]]])\n",
    "print t.shape\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 2, 1],\n",
       "       [1, 2, 1, 2]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
