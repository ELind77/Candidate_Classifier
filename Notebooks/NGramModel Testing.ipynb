{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from spacy.en import English\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/Storage/Coding_Projects/Candidate_Classifier'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/Storage/Coding_Projects/Candidate_Classifier'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-68fb219ad81b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcandidate_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnltk_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngram_classifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNgramClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcandidate_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/mnt/Storage/Coding_Projects/Candidate_Classifier/candidate_classifier/tokenizers.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnglish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/spacy/language.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_dir, vocab, tokenizer, tagger, parser, entity, matcher, serializer, load_vectors, package, vectors_package)\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentity\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparser\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmatcher\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/spacy/language.pyc\u001b[0m in \u001b[0;36mdefault_parser\u001b[1;34m(cls, package, vocab)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mParser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mArcEager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/spacy/syntax/parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.parser.Parser.from_dir (spacy/syntax/parser.cpp:5718)\u001b[1;34m()\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mproject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprojectivize\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'projectivize'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmoves\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/thinc/linear/avgtron.pyx\u001b[0m in \u001b[0;36mthinc.linear.avgtron.AveragedPerceptron.load (thinc/linear/avgtron.cpp:3151)\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                 \u001b[0mPyErr_CheckSignals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from candidate_classifier.string_processing import *\n",
    "from candidate_classifier.nltk_model.ngram_classifier import NgramClassifier\n",
    "\n",
    "from candidate_classifier.tokenizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import make_scorer, classification_report, f1_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "import codecs\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "fmt = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "hndlr = logging.StreamHandler()\n",
    "hndlr.setFormatter(fmt)\n",
    "logger.addHandler(hndlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents_path = 'candidate_classifier/data/processed/clean_sents.txt'\n",
    "labels_path = 'candidate_classifier/data/processed/sent_labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'BUSH', u'CARSON', u'CHRISTIE', u'CLINTON', u'CRUZ', u'KASICH', u'RUBIO', u'SANDERS', u'TRUMP']\n"
     ]
    }
   ],
   "source": [
    "with codecs.open(sents_path, mode='r', encoding='utf-8') as _f:\n",
    "    docs = [l.strip() for l in _f]\n",
    "\n",
    "with codecs.open(labels_path, mode='r', encoding='utf-8') as _f:\n",
    "    labels = [l.strip() for l in _f]\n",
    "\n",
    "candidates = sorted(list(set(labels)))\n",
    "print candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toknizrs = (simple_tokenizer,\n",
    "            lemmas_tokenizer, \n",
    "            lemmas_no_punct,\n",
    "            lemmas_merge_np,\n",
    "            lemmas_merge_ents,\n",
    "            lemmas_merge_np_merge_ents,\n",
    "            lemmas_cased_tokenizer,\n",
    "            lemmas_cased_merge_ents)\n",
    "\n",
    "ng_tokenizers1 = [TransformerABC(prefilter_substitutions=['strip'], tokenizer=t) for t in toknizrs]\n",
    "\n",
    "ng_tokenizers2 = [TransformerABC(prefilter_substitutions=['strip', 'lower'], tokenizer=t) for t in toknizrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng_data1 = [list(t(docs)) for t in ng_tokenizers1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ng_data2 = [list(t(docs)) for t in ng_tokenizers2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngram_pipe = Pipeline([\n",
    "        ('clf', OneVsOneClassifier(NgramClassifier(pad_ngrams=True)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_tokenizer\n",
      "[ 0.54421309  0.53359132  0.53997209]\n",
      "0.53925883617\n",
      "\n",
      "\n",
      "lemmas_tokenizer\n",
      "[ 0.57717623  0.5633713   0.58675491]\n",
      "0.575767479881\n",
      "\n",
      "\n",
      "lemmas_no_punct\n",
      "[ 0.57213578  0.55784761  0.58247465]\n",
      "0.570819346765\n",
      "\n",
      "\n",
      "lemmas_merge_np\n",
      "[ 0.56219524  0.54191144  0.55888021]\n",
      "0.554328964724\n",
      "\n",
      "\n",
      "lemmas_merge_ents\n",
      "[ 0.57936097  0.5676273   0.58711447]\n",
      "0.578034248422\n",
      "\n",
      "\n",
      "lemmas_merge_np_merge_ents\n",
      "[ 0.56193059  0.54320551  0.56146713]\n",
      "0.55553440775\n",
      "\n",
      "\n",
      "lemmas_cased_tokenizer\n",
      "[ 0.57684843  0.5633713   0.5867876 ]\n",
      "0.575669107958\n",
      "\n",
      "\n",
      "lemmas_cased_merge_ents\n",
      "[ 0.57936097  0.5676273   0.58711447]\n",
      "0.578034248422\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(ng_data2):\n",
    "    print toknizrs[i].func_name\n",
    "    scores = cross_val_score(ngram_pipe, np.asarray(d), y=labels, cv=3, scoring='f1_weighted')\n",
    "    print scores\n",
    "    print np.mean(scores)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57936097  0.5676273   0.58711447]\n",
      "0.578034248422\n"
     ]
    }
   ],
   "source": [
    "# Ratio calculated in normal space\n",
    "scores = cross_val_score(ngram_pipe, np.asarray(ng_data2[4]), y=labels, cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57936097  0.5676273   0.58711447]\n",
      "0.578034248422\n"
     ]
    }
   ],
   "source": [
    "# Ratio in normal space and predict_proba in normal space\n",
    "scores = cross_val_score(ngram_pipe, np.asarray(ng_data2[4]), y=labels, cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57520839  0.56867061  0.58508877]\n",
      "0.576322588505\n"
     ]
    }
   ],
   "source": [
    "# Ratio in normal space and predict_proba in normal space\n",
    "# data not lowercased\n",
    "scores = cross_val_score(ngram_pipe, np.asarray(ng_data1[4]), y=labels, cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57936097  0.5676273   0.58711447]\n",
      "0.578034248422\n"
     ]
    }
   ],
   "source": [
    "# Git version: aff3e929ec62bae7041130e447bfbc9b07f5567f\n",
    "scores = cross_val_score(ngram_pipe, np.asarray(ng_data2[4]), y=labels, cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57520839  0.56867061  0.58508877]\n",
      "0.576322588505\n"
     ]
    }
   ],
   "source": [
    "# Git version: aff3e929ec62bae7041130e447bfbc9b07f5567f\n",
    "# No lowercase\n",
    "scores = cross_val_score(ngram_pipe, np.asarray(ng_data1[4]), y=labels, cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57936097  0.5676273   0.58711447]\n",
      "0.578034248422\n"
     ]
    }
   ],
   "source": [
    "# Git version: aff3e929ec62bae7041130e447bfbc9b07f5567f\n",
    "# Scipy 17.1\n",
    "scores = cross_val_score(ngram_pipe, np.asarray(ng_data2[4]), y=labels, cv=3, scoring='f1_weighted')\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
